{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d640e572-234f-4cf1-aea0-bd9e8622a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196a4db4-0582-4ff7-8d11-3132f51d7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(200, input_shape=(10, 1), activation='relu'),  # Adjust input_shape based on your dataset\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c482f6d-a0e9-454b-a677-386883888966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    return pickle.loads(recvall(sock, msglen))\n",
    "\n",
    "def recvall(sock, n):\n",
    "    data = bytearray()\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data.extend(packet)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ec1bc5-85c2-4511-a22d-06f38a521961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening on localhost:12345\n",
      "Connected to client ('127.0.0.1', 54493)\n",
      "Received updated weights from client 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No model weights to average",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fbaaf0b05636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mglobal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'global_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mrun_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fbaaf0b05636>\u001b[0m in \u001b[0;36mrun_server\u001b[0;34m(host, port, clients)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Assuming client_handler returns and appends updated weights to client_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mglobal_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mglobal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updated global model with averaged weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fbaaf0b05636>\u001b[0m in \u001b[0;36mfederated_average\u001b[0;34m(models_weights)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Ensure there are models to average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodels_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No model weights to average\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Initialize average weights as the structure of the first model's weights, filled with zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No model weights to average"
     ]
    }
   ],
   "source": [
    "def federated_average(models_weights):\n",
    "    \"\"\"Compute the federated average of the models' weights.\"\"\"\n",
    "    # Ensure there are models to average\n",
    "    if not models_weights:\n",
    "        raise ValueError(\"No model weights to average\")\n",
    "\n",
    "    # Initialize average weights as the structure of the first model's weights, filled with zeros\n",
    "    average_weights = [np.zeros_like(weights) for weights in models_weights[0]]\n",
    "\n",
    "    # Sum up all model weights\n",
    "    for weights in models_weights:\n",
    "        for i, weight in enumerate(weights):\n",
    "            average_weights[i] += weight\n",
    "\n",
    "    # Divide by the number of models to get the average\n",
    "    for i in range(len(average_weights)):\n",
    "        average_weights[i] /= len(models_weights)\n",
    "\n",
    "    return average_weights\n",
    "\n",
    "\n",
    "def client_handler(connection, client_id, global_model):\n",
    "    # Send global model weights\n",
    "    weights = global_model.get_weights()\n",
    "    send_msg(connection, weights)\n",
    "    \n",
    "    # Receive updated weights from client\n",
    "    updated_weights = recv_msg(connection)\n",
    "    print(f\"Received updated weights from client {client_id}\")\n",
    "    \n",
    "    connection.close()\n",
    "    return updated_weights\n",
    "\n",
    "def run_server(host='localhost', port=12345, clients=1):\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(clients)\n",
    "    print(f\"Server listening on {host}:{port}\")\n",
    "\n",
    "    client_threads = []\n",
    "    client_models = []\n",
    "    global_model = create_lstm_model()\n",
    "    \n",
    "    for i in range(clients):\n",
    "        connection, address = server_socket.accept()\n",
    "        print(f\"Connected to client {address}\")\n",
    "        client_thread = Thread(target=client_handler, args=(connection, i, global_model))\n",
    "        client_threads.append(client_thread)\n",
    "        client_thread.start()\n",
    "\n",
    "    for thread in client_threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Assuming client_handler returns and appends updated weights to client_models\n",
    "    global_weights = federated_average(client_models)\n",
    "    global_model.set_weights(global_weights)\n",
    "    print(\"Updated global model with averaged weights\")\n",
    "\n",
    "    # Optionally, save the global model\n",
    "    global_model.save('global_model.h5')\n",
    "\n",
    "run_server()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
